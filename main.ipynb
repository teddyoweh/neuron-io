{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuio.tokenizer import Tokenizer\n",
    "from neuio.activation import ReLU\n",
    "from neuio.vectorizer import BuildVectors\n",
    "from neuio.linear import Linear\n",
    "class Softmax:\n",
    "    def __init__(self, dim=1):\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        exp_vals = np.exp(x - np.max(x, axis=self.dim, keepdims=True))\n",
    "        self.output = exp_vals / np.sum(exp_vals, axis=self.dim, keepdims=True)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        softmax_output = self.output\n",
    "        grad_input = grad_output * softmax_output * (1 - softmax_output)\n",
    "        return grad_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ReLU(nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super(ReLU, self).__init__()\n",
    "        self.inplace = inplace\n",
    "    def _max(self,x):\n",
    "        try:\n",
    "            return np.maximum(0,x)\n",
    "        except:\n",
    "            return 0\n",
    "    def forward(self, x):\n",
    "        return self._max(x)\n",
    "\n",
    "class Loss:\n",
    "    @staticmethod\n",
    "    def mean_squared_error(y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred)**2)\n",
    "    @staticmethod\n",
    "    def binary_cross_entropy(y_true, y_pred):\n",
    "        epsilon = 1e-7   \n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)   \n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    @staticmethod\n",
    "    def categorical_cross_entropy(y_true, y_pred):\n",
    "        epsilon = 1e-7   \n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)   \n",
    "        return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./twitter_training.csv')\n",
    "df = df.dropna()\n",
    "text_data = df['text']\n",
    "sentiment_data = df['sentiment']\n",
    "label_encoder = Tokenizer()\n",
    "sentiment_labels = label_encoder.fit_tokenize(sentiment_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = BuildVectors()\n",
    "train_vectors = vectorizer._fit_vectorize(text_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SentimentClassifier:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hidden = Linear(input_size, hidden_size)\n",
    "        self.relu = ReLU()\n",
    "        self.output = Linear(hidden_size, output_size)\n",
    "        self.softmax = Softmax(dim=1)\n",
    "        self.loss = Loss.categorical_cross_entropy\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.relu(self.hidden.forward(x))\n",
    "        output = self.softmax.forward(self.output.forward(hidden))\n",
    "        return output\n",
    "\n",
    "    def train(self, x, y, learning_rate=0.1, num_epochs=10):\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            output = self.forward(x)\n",
    "            loss = self.loss(output, y)\n",
    "            grad_output = self.softmax.backward(output - y)\n",
    "            grad_hidden = self.output.backward(grad_output, learning_rate)\n",
    "            grad_input = self.hidden.backward(grad_hidden, learning_rate)\n",
    "            \n",
    "            print(f\"Loss: {loss}\")\n",
    "    def predict(self, x):\n",
    "        output = self.forward(x)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "def shape(array):\n",
    "    if isinstance(array, list):\n",
    "        return (len(array),) + shape(array[0])\n",
    "    else:\n",
    "        return ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = shape(train_vectors)[1]\n",
    "hidden_size = 64\n",
    "output_size = len(label_encoder.classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier(input_size, hidden_size, output_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_vectors, sentiment_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(model, text):\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    \n",
    "    model.predict(text_vector)\n",
    "    # Get the predicted sentiment label\n",
    "    _, predicted_index = torch.max(output, 1)\n",
    "    predicted_label = label_encoder.inverse_transform(predicted_index.numpy())[0]\n",
    "\n",
    "    return predicted_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the predict_text function\n",
    "text = \"how are you\"\n",
    "predicted_sentiment = predict_text(model, text)\n",
    "print(f\"Predicted sentiment: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def custom_matmul(input1, input2):\n",
    "    # Get the dimensions of the input matrices\n",
    "    m1, n1 = input1.shape\n",
    "    m2, n2 = input2.shape\n",
    "\n",
    "    # Check if the matrices can be multiplied\n",
    "    if n1 != m2:\n",
    "        raise ValueError(\"Invalid matrix dimensions for multiplication\")\n",
    "\n",
    "    # Create an empty result matrix\n",
    "    result = np.zeros((m1, n2))\n",
    "\n",
    "    # Perform matrix multiplication\n",
    "    for i in range(m1):\n",
    "        for j in range(n2):\n",
    "            for k in range(n1):\n",
    "                result[i, j] += input1[i, k] * input2[k, j]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "result = custom_matmul(A, B)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
